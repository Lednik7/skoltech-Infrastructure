{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov 25 00:27:00 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3090 Ti     Off | 00000000:0B:00.0  On |                  Off |\r\n",
      "|  0%   46C    P5              44W / 480W |   2123MiB / 24564MiB |     10%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A      3066      G   /usr/lib/xorg/Xorg                          417MiB |\r\n",
      "|    0   N/A  N/A      3221      G   /usr/bin/gnome-shell                         84MiB |\r\n",
      "|    0   N/A  N/A      5179      G   ...sktop/5248/usr/bin/telegram-desktop        4MiB |\r\n",
      "|    0   N/A  N/A      5215    C+G   ...497572824,964712838452912400,262144      385MiB |\r\n",
      "|    0   N/A  N/A      6013      G   ...ures=SpareRendererForSitePerProcess       71MiB |\r\n",
      "|    0   N/A  N/A     12591      G   ...,WinRetrieveSuggestionsOnlyOnDemand       40MiB |\r\n",
      "|    0   N/A  N/A     21668      C   ...tech-Infrastructure/venv/bin/python     1080MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "!nvidia-smi"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:00.472968311Z",
     "start_time": "2023-11-24T21:27:00.234848674Z"
    }
   },
   "id": "24045571e1324f9d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from src.utils import set_seed\n",
    "\n",
    "set_seed(42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:01.534982705Z",
     "start_time": "2023-11-24T21:27:00.473989066Z"
    }
   },
   "id": "ea14c76c9a7f9f89"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "21"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "#TODO: Если не созданы тайлы, то надо запустить src/preprocessing/tile_generating.py\n",
    "\n",
    "tiles_folders = glob.glob(\"../data/digital_leaders/tiles/*\")\n",
    "len(tiles_folders)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:01.541717454Z",
     "start_time": "2023-11-24T21:27:01.535126582Z"
    }
   },
   "id": "8b692ab2adadddf2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['train_image_019', 'train_image_010', 'train_image_006', 'train_image_007', 'train_image_013', 'train_image_000', 'train_image_020', 'train_image_015', 'train_image_017', 'train_image_002', 'train_image_011', 'train_image_016', 'train_image_008', 'train_image_003', 'train_image_014', 'train_image_018']\n",
      "Val: ['train_image_004', 'train_image_012', 'train_image_001', 'train_image_005', 'train_image_009']\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0, 0)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "train_folders, val_folders = train_test_split(tiles_folders, test_size=0.2)\n",
    "print(f\"Train: {[os.path.basename(x) for x in train_folders]}\")\n",
    "print(f\"Val: {[os.path.basename(x) for x in val_folders]}\")\n",
    "train_paths = []\n",
    "val_paths = []\n",
    "for folder in train_folders:\n",
    "    train_paths.extend(glob.glob(os.path.join(folder, \"images\", \"*.png\")))\n",
    "for folder in val_folders:\n",
    "    val_paths.extend(glob.glob(os.path.join(folder, \"images\", \"*.png\")))\n",
    "len(train_paths), len(val_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:01.855085138Z",
     "start_time": "2023-11-24T21:27:01.541012598Z"
    }
   },
   "id": "9d3f208bf26571b4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class TileDataset(Dataset):\n",
    "    def __init__(self, paths, transforms=None):\n",
    "        self.paths = paths\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask_path = path.replace(\"images\", \"masks\").replace(\"tile_\", \"mask_tile_\")\n",
    "        mask = cv2.imread(mask_path)[:, :, 0]\n",
    "        mask = np.expand_dims(mask, axis=-1)\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image, mask=mask)\n",
    "            image = transformed[\"image\"]\n",
    "            mask = transformed[\"mask\"]\n",
    "        return image, mask"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:01.902286208Z",
     "start_time": "2023-11-24T21:27:01.858433271Z"
    }
   },
   "id": "175b8be1a4f0c57b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(256, 256),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(256, 256),\n",
    "        A.Normalize(),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:02.304185165Z",
     "start_time": "2023-11-24T21:27:01.878924501Z"
    }
   },
   "id": "82fdcf1e1e8f3a54"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "train_dataset = TileDataset(train_paths, train_transforms)\n",
    "val_dataset = TileDataset(val_paths, val_transforms)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:02.308370715Z",
     "start_time": "2023-11-24T21:27:02.306945220Z"
    }
   },
   "id": "fa99e90c24fbc97c"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def chw2hwc(image: torch.Tensor) -> torch.Tensor:\n",
    "    return image.permute(1, 2, 0)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:02.320248350Z",
     "start_time": "2023-11-24T21:27:02.309793206Z"
    }
   },
   "id": "9fa26433fba1f132"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k = 0\n",
    "for image, mask in train_dataset:\n",
    "    plt.subplots(1, 2)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(chw2hwc(image))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "    k += 1\n",
    "    if k == 3:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:02.511154339Z",
     "start_time": "2023-11-24T21:27:02.322058540Z"
    }
   },
   "id": "53664d8e059ac970"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DataLoader\n\u001B[1;32m      3\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m16\u001B[39m\n\u001B[0;32m----> 4\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpin_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m      6\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m val_loader \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[1;32m      9\u001B[0m     val_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, pin_memory\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     10\u001B[0m )\n",
      "File \u001B[0;32m~/PycharmProjects/skoltech-Infrastructure/venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:349\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[1;32m    347\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# map-style\u001B[39;00m\n\u001B[1;32m    348\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[0;32m--> 349\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m \u001B[43mRandomSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    350\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    351\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/skoltech-Infrastructure/venv/lib/python3.11/site-packages/torch/utils/data/sampler.py:140\u001B[0m, in \u001B[0;36mRandomSampler.__init__\u001B[0;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement should be a boolean value, but got replacement=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 140\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mValueError\u001B[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=1, pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:02.782946801Z",
     "start_time": "2023-11-24T21:27:02.513739018Z"
    }
   },
   "id": "dab6de48fd5ea465"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torchgeo.models import ResNet50_Weights\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "weights = ResNet50_Weights.SENTINEL2_RGB_MOCO\n",
    "model = smp.DeepLabV3Plus(encoder_name=\"resnet50\", encoder_weights=None,\n",
    "                          in_channels=weights.meta[\"in_chans\"], classes=1,\n",
    "                          activation=\"sigmoid\")\n",
    "model.encoder.load_state_dict(weights.get_state_dict(), strict=False)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T21:27:02.830840572Z"
    }
   },
   "id": "8d87a77e5ddd9f45"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.modelling.metrics import DiceMetric, IoULoss\n",
    "\n",
    "criterion = IoULoss()\n",
    "metric = DiceMetric()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T21:27:02.830927457Z"
    }
   },
   "id": "e32ef364d8331903"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "epochs = 10\n",
    "lr = 3e-4\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=lr, epochs=epochs,\n",
    "                       steps_per_epoch=len(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T21:27:02.830955114Z"
    }
   },
   "id": "34fcbf6b91f4c8e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from src.modelling.train import run\n",
    "\n",
    "run(model=model, train_loader=train_loader, val_loader=val_loader,\n",
    "    criterion=criterion, metric=metric, optimizer=optimizer,\n",
    "    scheduler=scheduler, epochs=epochs, device=device,\n",
    "    save_name=\"deeplab+_rn50_MOCO.pth\", weights_path=\"../artifacts/weights\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T21:27:02.830981096Z"
    }
   },
   "id": "4c0c5c97e91dcd3d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T21:27:02.831085861Z",
     "start_time": "2023-11-24T21:27:02.831006659Z"
    }
   },
   "id": "410cf2aa93015f39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
